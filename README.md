# ğŸ§  Pistachio Classification â€“ Deep Learning Optimization Project

## ğŸš€ Overview

Ce projet prÃ©sente une implÃ©mentation complÃ¨te dâ€™un pipeline de Deep Learning dÃ©diÃ© Ã  la classification automatique de pistaches Ã  partir de caractÃ©ristiques numÃ©riques.

Lâ€™objectif est double :

* Construire un modÃ¨le MLP robuste pour la classification supervisÃ©e.
* Optimiser rigoureusement ses hyperparamÃ¨tres via Optuna afin de maximiser la performance tout en contrÃ´lant la gÃ©nÃ©ralisation.

Le projet adopte une approche mÃ©thodologique structurÃ©e : modÃ©lisation, rÃ©gularisation, optimisation, Ã©valuation statistique et analyse de robustesse.

---

## ğŸ¯ Objectif

DÃ©velopper un modÃ¨le de classification performant capable de :

* Maximiser la validation accuracy
* Minimiser le surapprentissage
* Maintenir une bonne capacitÃ© de gÃ©nÃ©ralisation
* Analyser finement les effets des hyperparamÃ¨tres

---

## ğŸ“Š Dataset

Le dataset contient des caractÃ©ristiques numÃ©riques dÃ©crivant des pistaches.

Pipeline appliquÃ© :

* VÃ©rification des distributions
* Analyse des classes
* Normalisation des variables
* Split train / validation / test
* Encodage adaptÃ© aux labels

---

## ğŸ—ï¸ Architecture du ModÃ¨le

ModÃ¨le : Multi-Layer Perceptron (MLP)

Architecture optimale trouvÃ©e :

* 3 couches cachÃ©es
* 64 â†’ 96 â†’ 128 neurones
* Activation : ReLU
* Batch Normalization
* Dropout â‰ˆ 0.34
* RÃ©gularisation L2
* Optimizer : RMSprop
* Learning rate â‰ˆ 0.00142

Validation Accuracy optimale : 96.22 %

---

## ğŸ”¬ Optimisation des HyperparamÃ¨tres

MÃ©thode : Optuna (TPE Sampler)

Espace explorÃ© :

* Nombre de couches
* Nombre de neurones par couche
* Dropout
* Learning rate
* Optimizer
* L2 regularization
* Weight decay
* Batch size

DurÃ©e dâ€™optimisation : 26.42 minutes
Nombre de trials : exploratoire adaptatif

---

## ğŸ“ˆ RÃ©sultats

Le modÃ¨le final obtient :

* Validation Accuracy : 96.22 %
* Performance stable sur le test set
* Courbe ROC cohÃ©rente
* Matrice de confusion Ã©quilibrÃ©e
* Lift curve significative

Les analyses graphiques incluent :

* ROC Curve
* Confusion Matrix
* Lift Curve
* Impact du learning rate
* Impact du weight decay
* Distribution des prÃ©dictions
* Courbes dâ€™apprentissage

---

## ğŸ§  Analyse & InterprÃ©tation

* Le modÃ¨le prÃ©sente une excellente sÃ©paration des classes.
* La rÃ©gularisation L2 + Dropout rÃ©duit efficacement lâ€™overfitting.
* Lâ€™optimisation hyperparamÃ©trique amÃ©liore significativement la robustesse.
* Lâ€™architecture progressive (64 â†’ 96 â†’ 128) favorise une extraction hiÃ©rarchique des reprÃ©sentations.

La stabilitÃ© des performances indique une bonne capacitÃ© de gÃ©nÃ©ralisation.

---

## ğŸ› ï¸ Stack Technique

* Python
* TensorFlow / Keras
* Optuna
* NumPy / Pandas
* Matplotlib / Seaborn
* Kaggle GPU Environment

---

## ğŸ“¦ Outputs GÃ©nÃ©rÃ©s

* best_pistachio_model.h5
* Courbes ROC
* Matrices de confusion
* Lift curve
* Analyses dâ€™impact hyperparamÃ¨tres
* Visualisations dâ€™optimisation

---

## ğŸ“Œ Conclusion

Ce projet dÃ©montre lâ€™importance :

* dâ€™une architecture bien rÃ©gularisÃ©e
* dâ€™une optimisation hyperparamÃ©trique mÃ©thodique
* dâ€™une analyse statistique rigoureuse des performances

La combinaison modÃ©lisation + optimisation + interprÃ©tation constitue une approche complÃ¨te et scientifiquement cohÃ©rente.

---

## ğŸ” Perspectives

* Validation croisÃ©e K-fold
* Comparaison avec modÃ¨les CNN si donnÃ©es image
* SHAP / Feature importance
* Calibration probabiliste
* Ensemble learning

